# agentZERO-ollama

ğŸ¤– **En agentic Ollama-basert AI-agent fokusert pÃ¥ prompt-prosessering**

AgentZERO-ollama er en lightweight, lokal AI-agent som bruker smÃ¥ Ollama-modeller (under 500MB) for effektiv prompt-prosessering og agentic oppgaver. Systemet er designet for Ã¥ kjÃ¸re pÃ¥ beskjedne maskinvareressurser mens det leverer kraftig AI-funksjonalitet.

## ğŸ¯ Hovedfunksjoner

- **3 Optimaliserte Modeller**: SmolLM 135M (92MB), SmolLM 360M (229MB), og SmolLM 1.7B (991MB)
- **Prompt Engineering**: Avansert prompt-prosessering og optimalisering
- **Agentic Workflow**: Multi-step oppgavelÃ¸sning med intelligent planlegging
- **Lokal KjÃ¸ring**: Ingen data sendes til eksterne servere
- **Lightweight**: Fungerer pÃ¥ standard laptops og desktop-maskiner
- **Cyberpunk UI**: Moderne, terminal-inspirert brukergrensesnitt

## ğŸ—ï¸ Arkitektur

```
agentZERO-ollama/
â”œâ”€â”€ agents/                 # Agent-definisjonsfiler
â”‚   â”œâ”€â”€ planner.py         # Planleggingsagent
â”‚   â”œâ”€â”€ executor.py        # UtfÃ¸relsesagent
â”‚   â””â”€â”€ processor.py       # Prompt-prosesseringsagent
â”œâ”€â”€ models/                # Modellkonfigurasjon
â”‚   â”œâ”€â”€ smollm_135m.yaml   # SmolLM 135M konfigurasjon
â”‚   â”œâ”€â”€ smollm_360m.yaml   # SmolLM 360M konfigurasjon
â”‚   â””â”€â”€ smollm_1.7b.yaml   # SmolLM 1.7B konfigurasjon
â”œâ”€â”€ prompts/               # Prompt-templates
â”‚   â”œâ”€â”€ system/            # System prompts
â”‚   â”œâ”€â”€ task/              # Oppgave-spesifikke prompts
â”‚   â””â”€â”€ optimization/      # Prompt-optimaliseringsregler
â”œâ”€â”€ ui/                    # Brukergrensesnitt
â”‚   â”œâ”€â”€ app.py            # Hovedapplikasjon
â”‚   â”œâ”€â”€ static/           # CSS, JS, bilder
â”‚   â””â”€â”€ templates/        # HTML-templates
â”œâ”€â”€ core/                  # Kjernefunksjonalitet
â”‚   â”œâ”€â”€ ollama_client.py  # Ollama API-klient
â”‚   â”œâ”€â”€ prompt_engine.py  # Prompt-prosessering
â”‚   â””â”€â”€ agent_manager.py  # Agent-koordinering
â””â”€â”€ docker/               # Docker-konfigurasjon
    â”œâ”€â”€ Dockerfile
    â””â”€â”€ docker-compose.yml
```

## ğŸš€ Rask Start

### Forutsetninger

- Python 3.9+
- Docker (valgfritt)
- Ollama installert lokalt

### Installasjon

1. **Klon repositoriet:**
```bash
git clone https://github.com/yourusername/agentZERO-ollama.git
cd agentZERO-ollama
```

2. **Installer avhengigheter:**
```bash
pip install -r requirements.txt
```

3. **Last ned Ollama-modeller:**
```bash
ollama pull smollm:135m
ollama pull smollm:360m
ollama pull smollm:1.7b
```

4. **Start applikasjonen:**
```bash
python ui/app.py
```

5. **Ã…pne nettleseren:**
GÃ¥ til `http://localhost:8080`

## ğŸ® Bruk

### Grunnleggende Chat
```python
from core.agent_manager import AgentManager

agent = AgentManager(model="smollm:135m")
response = agent.process("Skriv en kort historie om en robot")
print(response)
```

### Avansert Prompt-prosessering
```python
from core.prompt_engine import PromptEngine

engine = PromptEngine()
optimized_prompt = engine.optimize(
    original="Forklar kvantedatabehandling",
    target_model="smollm:360m",
    complexity="intermediate"
)
```

### Multi-Agent Workflow
```python
from agents.planner import PlannerAgent
from agents.executor import ExecutorAgent

planner = PlannerAgent(model="smollm:1.7b")
executor = ExecutorAgent(model="smollm:360m")

plan = planner.create_plan("Lag en enkel nettside")
result = executor.execute_plan(plan)
```

## ğŸ§  Modell-spesifikasjoner

| Modell | StÃ¸rrelse | Parametere | BruksomrÃ¥de | RAM-krav |
|--------|-----------|------------|-------------|----------|
| SmolLM 135M | 92MB | 135M | Rask respons, enkle oppgaver | 1GB |
| SmolLM 360M | 229MB | 360M | Balansert ytelse/hastighet | 2GB |
| SmolLM 1.7B | 991MB | 1.7B | Komplekse oppgaver, resonnering | 4GB |

## ğŸ¨ Prompt-prosessering Funksjoner

### Automatisk Optimalisering
- **Modell-spesifikk tilpasning**: Prompts optimaliseres for hver modells styrker
- **Kontekst-komprimering**: Reduserer token-bruk uten Ã¥ miste informasjon
- **Template-system**: Gjenbrukbare prompt-templates for vanlige oppgaver

### Intelligent Routing
- **Oppgave-analyse**: Automatisk valg av beste modell for oppgaven
- **Load balancing**: Fordeler oppgaver basert pÃ¥ modell-tilgjengelighet
- **Fallback-system**: Automatisk nedgradering ved ressursmangel

### Prompt Engineering Tools
- **A/B Testing**: Sammenlign prompt-varianter
- **YtelsesmÃ¥linger**: Spor responstid og kvalitet
- **Iterativ forbedring**: LÃ¦r fra tidligere interaksjoner

## ğŸ”§ Konfigurasjon

### Modell-konfigurasjon (models/smollm_135m.yaml)
```yaml
model:
  name: "smollm:135m"
  max_tokens: 2048
  temperature: 0.7
  top_p: 0.9
  
prompts:
  system: "Du er en hjelpsom AI-assistent som gir korte, presise svar."
  max_length: 512
  
performance:
  timeout: 30
  retry_attempts: 3
```

### Agent-konfigurasjon
```yaml
agents:
  planner:
    model: "smollm:1.7b"
    role: "strategic_planning"
    max_steps: 10
    
  executor:
    model: "smollm:360m"
    role: "task_execution"
    parallel_tasks: 3
    
  processor:
    model: "smollm:135m"
    role: "prompt_optimization"
    cache_enabled: true
```

## ğŸ³ Docker Deployment

```bash
# Bygg og start med Docker Compose
docker-compose up --build

# Eller bygg manuelt
docker build -t agentzero-ollama .
docker run -p 8080:8080 -v ollama_models:/root/.ollama agentzero-ollama
```

## ğŸ“Š Ytelse og Benchmarks

### Responstider (gjennomsnitt)
- **SmolLM 135M**: ~200ms
- **SmolLM 360M**: ~500ms  
- **SmolLM 1.7B**: ~1.2s

### Minnebruk
- **Basis system**: ~500MB RAM
- **Med alle modeller**: ~2.5GB RAM
- **Disk space**: ~1.5GB total

## ğŸ› ï¸ Utvikling

### Legg til ny agent
```python
from core.base_agent import BaseAgent

class CustomAgent(BaseAgent):
    def __init__(self, model="smollm:360m"):
        super().__init__(model)
        self.role = "custom_task"
    
    def process_task(self, task):
        prompt = self.build_prompt(task)
        return self.generate_response(prompt)
```

### Lag custom prompt template
```yaml
# prompts/custom/my_template.yaml
template:
  name: "code_generation"
  description: "Genererer kode basert pÃ¥ beskrivelse"
  
system_prompt: |
  Du er en ekspert programmerer. Generer ren, kommentert kode.
  
user_template: |
  Oppgave: {task}
  SprÃ¥k: {language}
  Kompleksitet: {complexity}
  
  Generer kode som lÃ¸ser denne oppgaven.
```

## ğŸ¤ Bidrag

Vi Ã¸nsker bidrag! Se [CONTRIBUTING.md](CONTRIBUTING.md) for retningslinjer.

### Utviklingsoppsett
```bash
# Klon repo
git clone https://github.com/yourusername/agentZERO-ollama.git
cd agentZERO-ollama

# Opprett virtual environment
python -m venv venv
source venv/bin/activate  # Linux/Mac
# eller
venv\Scripts\activate     # Windows

# Installer dev-avhengigheter
pip install -r requirements-dev.txt

# KjÃ¸r tester
pytest tests/
```

## ğŸ“ Lisens

MIT License - se [LICENSE](LICENSE) for detaljer.

## ğŸ™ Takk til

- [Ollama](https://ollama.ai/) for den fantastiske lokale LLM-plattformen
- [SmolLM](https://huggingface.co/HuggingFaceTB/SmolLM-135M) for de effektive smÃ¥ modellene
- Agent Zero community for inspirasjon

## ğŸ“ Support

- ğŸ› **Issues**: [GitHub Issues](https://github.com/yourusername/agentZERO-ollama/issues)
- ğŸ’¬ **Diskusjoner**: [GitHub Discussions](https://github.com/yourusername/agentZERO-ollama/discussions)
- ğŸ“§ **Email**: support@agentzero-ollama.com

---

**AgentZERO-ollama** - Kraftig AI, minimal fotavtrykk. ğŸš€

